{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "...load BASNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37a6a0dd90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jruano/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jruano/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/jruano/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/jruano/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/jruano/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Number is 0\n",
      "inferencing image: 1\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 1\n",
      "inferencing image: 2\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 2\n",
      "inferencing image: 3\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 3\n",
      "inferencing image: 4\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 4\n",
      "inferencing image: 5\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 5\n",
      "inferencing image: 6\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 6\n",
      "inferencing image: 7\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 7\n",
      "inferencing image: 8\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 8\n",
      "inferencing image: 9\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 9\n",
      "inferencing image: 10\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 10\n",
      "inferencing image: 11\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 11\n",
      "inferencing image: 12\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 12\n",
      "inferencing image: 13\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 13\n",
      "inferencing image: 14\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 14\n",
      "inferencing image: 15\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 15\n",
      "inferencing image: 16\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 16\n",
      "inferencing image: 17\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 17\n",
      "inferencing image: 18\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 18\n",
      "inferencing image: 19\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 19\n",
      "inferencing image: 20\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 20\n",
      "inferencing image: 21\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 21\n",
      "inferencing image: 22\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 22\n",
      "inferencing image: 23\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 23\n",
      "inferencing image: 24\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 24\n",
      "inferencing image: 25\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 25\n",
      "inferencing image: 26\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 26\n",
      "inferencing image: 27\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 27\n",
      "inferencing image: 28\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 28\n",
      "inferencing image: 29\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 29\n",
      "inferencing image: 30\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 30\n",
      "inferencing image: 31\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 31\n",
      "inferencing image: 32\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 32\n",
      "inferencing image: 33\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 33\n",
      "inferencing image: 34\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 34\n",
      "inferencing image: 35\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 35\n",
      "inferencing image: 36\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 36\n",
      "inferencing image: 37\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 37\n",
      "inferencing image: 38\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 38\n",
      "inferencing image: 39\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 39\n",
      "inferencing image: 40\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 40\n",
      "inferencing image: 41\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 41\n",
      "inferencing image: 42\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 42\n",
      "inferencing image: 43\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 43\n",
      "inferencing image: 44\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 44\n",
      "inferencing image: 45\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 45\n",
      "inferencing image: 46\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 46\n",
      "inferencing image: 47\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 47\n",
      "inferencing image: 48\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 48\n",
      "inferencing image: 49\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 49\n",
      "inferencing image: 50\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 50\n",
      "inferencing image: 51\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 51\n",
      "inferencing image: 52\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 52\n",
      "inferencing image: 53\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 53\n",
      "inferencing image: 54\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 54\n",
      "inferencing image: 55\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 55\n",
      "inferencing image: 56\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 56\n",
      "inferencing image: 57\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 57\n",
      "inferencing image: 58\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 58\n",
      "inferencing image: 59\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 59\n",
      "inferencing image: 60\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 60\n",
      "inferencing image: 61\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 61\n",
      "inferencing image: 62\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 62\n",
      "inferencing image: 63\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 63\n",
      "inferencing image: 64\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 64\n",
      "inferencing image: 65\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 65\n",
      "inferencing image: 66\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 66\n",
      "inferencing image: 67\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 67\n",
      "inferencing image: 68\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 68\n",
      "inferencing image: 69\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 69\n",
      "inferencing image: 70\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 70\n",
      "inferencing image: 71\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 71\n",
      "inferencing image: 72\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 72\n",
      "inferencing image: 73\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 73\n",
      "inferencing image: 74\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 74\n",
      "inferencing image: 75\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 75\n",
      "inferencing image: 76\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 76\n",
      "inferencing image: 77\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 77\n",
      "inferencing image: 78\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 78\n",
      "inferencing image: 79\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 79\n",
      "inferencing image: 80\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 80\n",
      "inferencing image: 81\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 81\n",
      "inferencing image: 82\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 82\n",
      "inferencing image: 83\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 83\n",
      "inferencing image: 84\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 84\n",
      "inferencing image: 85\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 85\n",
      "inferencing image: 86\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 86\n",
      "inferencing image: 87\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 87\n",
      "inferencing image: 88\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 88\n",
      "inferencing image: 89\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 89\n",
      "inferencing image: 90\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 90\n",
      "inferencing image: 91\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 91\n",
      "inferencing image: 92\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 92\n",
      "inferencing image: 93\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 93\n",
      "inferencing image: 94\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 94\n",
      "inferencing image: 95\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 95\n",
      "inferencing image: 96\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 96\n",
      "inferencing image: 97\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 97\n",
      "inferencing image: 98\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 98\n",
      "inferencing image: 99\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 99\n",
      "inferencing image: 100\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 100\n",
      "inferencing image: 101\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 101\n",
      "inferencing image: 102\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 102\n",
      "inferencing image: 103\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 103\n",
      "inferencing image: 104\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 104\n",
      "inferencing image: 105\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 105\n",
      "inferencing image: 106\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 106\n",
      "inferencing image: 107\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 107\n",
      "inferencing image: 108\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 108\n",
      "inferencing image: 109\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 109\n",
      "inferencing image: 110\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 110\n",
      "inferencing image: 111\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 111\n",
      "inferencing image: 112\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 112\n",
      "inferencing image: 113\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 113\n",
      "inferencing image: 114\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 114\n",
      "inferencing image: 115\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 115\n",
      "inferencing image: 116\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 116\n",
      "inferencing image: 117\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 117\n",
      "inferencing image: 118\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 118\n",
      "inferencing image: 119\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 119\n",
      "inferencing image: 120\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 120\n",
      "inferencing image: 121\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 121\n",
      "inferencing image: 122\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 122\n",
      "inferencing image: 123\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 123\n",
      "inferencing image: 124\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 124\n",
      "inferencing image: 125\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 125\n",
      "inferencing image: 126\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 126\n",
      "inferencing image: 127\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 127\n",
      "inferencing image: 128\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 128\n",
      "inferencing image: 129\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 129\n",
      "inferencing image: 130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 130\n",
      "inferencing image: 131\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 131\n",
      "inferencing image: 132\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 132\n",
      "inferencing image: 133\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 133\n",
      "inferencing image: 134\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 134\n",
      "inferencing image: 135\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 135\n",
      "inferencing image: 136\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 136\n",
      "inferencing image: 137\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 137\n",
      "inferencing image: 138\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 138\n",
      "inferencing image: 139\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 139\n",
      "inferencing image: 140\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 140\n",
      "inferencing image: 141\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 141\n",
      "inferencing image: 142\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 142\n",
      "inferencing image: 143\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 143\n",
      "inferencing image: 144\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 144\n",
      "inferencing image: 145\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 145\n",
      "inferencing image: 146\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 146\n",
      "inferencing image: 147\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 147\n",
      "inferencing image: 148\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 148\n",
      "inferencing image: 149\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 149\n",
      "inferencing image: 150\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 150\n",
      "inferencing image: 151\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 151\n",
      "inferencing image: 152\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 152\n",
      "inferencing image: 153\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 153\n",
      "inferencing image: 154\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 154\n",
      "inferencing image: 155\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 155\n",
      "inferencing image: 156\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 156\n",
      "inferencing image: 157\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 157\n",
      "inferencing image: 158\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 158\n",
      "inferencing image: 159\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 159\n",
      "inferencing image: 160\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 160\n",
      "inferencing image: 161\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 161\n",
      "inferencing image: 162\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 162\n",
      "inferencing image: 163\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 163\n",
      "inferencing image: 164\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 164\n",
      "inferencing image: 165\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 165\n",
      "inferencing image: 166\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 166\n",
      "inferencing image: 167\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 167\n",
      "inferencing image: 168\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 168\n",
      "inferencing image: 169\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 169\n",
      "inferencing image: 170\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 170\n",
      "inferencing image: 171\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 171\n",
      "inferencing image: 172\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 172\n",
      "inferencing image: 173\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 173\n",
      "inferencing image: 174\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 174\n",
      "inferencing image: 175\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 175\n",
      "inferencing image: 176\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 176\n",
      "inferencing image: 177\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 177\n",
      "inferencing image: 178\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 178\n",
      "inferencing image: 179\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 179\n",
      "inferencing image: 180\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 180\n",
      "inferencing image: 181\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 181\n",
      "inferencing image: 182\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 182\n",
      "inferencing image: 183\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 183\n",
      "inferencing image: 184\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 184\n",
      "inferencing image: 185\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 185\n",
      "inferencing image: 186\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 186\n",
      "inferencing image: 187\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 187\n",
      "inferencing image: 188\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 188\n",
      "inferencing image: 189\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 189\n",
      "inferencing image: 190\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 190\n",
      "inferencing image: 191\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 191\n",
      "inferencing image: 192\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 192\n",
      "inferencing image: 193\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 193\n",
      "inferencing image: 194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 194\n",
      "inferencing image: 195\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 195\n",
      "inferencing image: 196\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 196\n",
      "inferencing image: 197\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 197\n",
      "inferencing image: 198\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 198\n",
      "inferencing image: 199\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "Frame Number is 199\n",
      "inferencing image: 200\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n",
      "torch.Size([1, 1, 256, 256])\n",
      "(960, 540, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import ffmpeg\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "from data_loader_jorge import RescaleT\n",
    "from data_loader_jorge import CenterCrop\n",
    "from data_loader_jorge import ToTensor\n",
    "from data_loader_jorge import ToTensorLab\n",
    "from data_loader_jorge import SalObjDatasetFromMem\n",
    "\n",
    "from model import BASNet\n",
    "\n",
    "#functions area \n",
    "\n",
    "def normPRED(d):\n",
    "\tma = torch.max(d)\n",
    "\tmi = torch.min(d)\n",
    "\n",
    "\tdn = (d-mi)/(ma-mi)\n",
    "\n",
    "\treturn dn\n",
    "\n",
    "def save_output(image_name,pred,d_dir):\n",
    "\n",
    "\tpredict = pred\n",
    "\tpredict = predict.squeeze()\n",
    "\tpredict_np = predict.cpu().data.numpy()\n",
    "\n",
    "\tim = Image.fromarray(predict_np*255).convert('RGB')\n",
    "\timg_name = image_name.split(\"/\")[-1]\n",
    "\timage = io.imread(image_name)\n",
    "\timo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
    "\n",
    "\tpb_np = np.array(imo)\n",
    "\n",
    "\taaa = img_name.split(\".\")\n",
    "\tbbb = aaa[0:-1]\n",
    "\timidx = bbb[0]\n",
    "\tfor i in range(1,len(bbb)):\n",
    "\t\timidx = imidx + \".\" + bbb[i]\n",
    "\n",
    "\timo.save(d_dir+imidx+'.png')\n",
    "    \n",
    "def enmask(in_array):\n",
    "    \n",
    "    out_array= np.zeros(shape=(in_array.shape[0],in_array.shape[1]), dtype=bool)\n",
    "    return 1\n",
    "\n",
    "\n",
    "def transform_pred(image,pred,d_dir):\n",
    "\n",
    "\tpredict = pred\n",
    "\tpredict = predict.squeeze()\n",
    "\tpredict_np = predict.cpu().data.numpy()\n",
    "\tpredict_np2 = np.round(predict_np,0)\n",
    "    \n",
    "\n",
    "\n",
    "\tim = Image.fromarray(predict_np*255).convert('RGB')\n",
    "#\timg_name = image_name.split(\"/\")[-1]\n",
    "#\timage = io.imread(image_name)\n",
    "\timo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
    "\n",
    "\tpb_np = np.array(imo)\n",
    "#\tpb_np2=enmask(pb_np)\n",
    "\tprint(pb_np.shape)\n",
    "\n",
    "#\taaa = img_name.split(\".\")\n",
    "#\tbbb = aaa[0:-1]\n",
    "#\timidx = bbb[0]\n",
    "#\tfor i in range(1,len(bbb)):\n",
    "#\t\timidx = imidx + \".\" + bbb[i]\n",
    "\n",
    "#\tf_name=d_dir+imidx+'.jpg'\n",
    "#\timo.save(f_name)\n",
    "   \n",
    "\treturn pb_np\n",
    "    \n",
    "def process_image(img):\n",
    "    \n",
    "   test_salobj_dataset = SalObjDatasetFromMem(img_in = img, lbl = [],transform=transforms.Compose([RescaleT(256),ToTensorLab(flag=0)]))\n",
    "   test_salobj_dataloader = DataLoader(test_salobj_dataset, batch_size=1,shuffle=False,num_workers=1)\n",
    "   \n",
    "   for i_test, data_test in enumerate(test_salobj_dataloader):\n",
    "\n",
    "      inputs_test = data_test['image']\n",
    "      inputs_test = inputs_test.type(torch.FloatTensor)\n",
    "\n",
    "      if torch.cuda.is_available():\n",
    "          inputs_test = Variable(inputs_test.cuda())\n",
    "      else:\n",
    "          inputs_test = Variable(inputs_test)\n",
    "\n",
    "      d1,d2,d3,d4,d5,d6,d7,d8 = net(inputs_test)\n",
    "\n",
    "      print(d1.shape)\n",
    "   # normalization\n",
    "      pred = d1[:,0,:,:]\n",
    "      pred = normPRED(pred)\n",
    "   # save results to test_results folder\n",
    "      img_ret=transform_pred(img,pred,prediction_dir)\n",
    "      del d1,d2,d3,d4,d5,d6,d7,d8\n",
    "   return img_ret\n",
    "\n",
    "\n",
    "def generate_thumbnail(in_filename, out_filename, time, width):\n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(in_filename, ss=time)\n",
    "            .filter('scale', width, -1)\n",
    "            .output(out_filename, vframes=1)\n",
    "            .overwrite_output()\n",
    "            .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr.decode(), file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "        \n",
    "#main\n",
    "\n",
    "#imgtest=cv2.imread(\"./prediction/image2.jpg\")\n",
    "#cv2.imshow(\"prueba\",imgtest)\n",
    "#cv2.waitKey(0)\n",
    "#1 definitions\n",
    "print(\"hola\")\n",
    "model_dir = './saved_models/basnet_bsi/basnet.pth'\n",
    "input_file= \"/home/jruano/devs/videos/violin5.mp4\"\n",
    "input_file2= \"/home/jruano/devs/videos/guitar2.mp4\"\n",
    "\n",
    "bkg_file=\"/home/jruano/Pictures/sunset.jpg\"\n",
    "output_video=\"video_comp.mp4\"\n",
    "video_prueba=\"video_test2.mp4\"\n",
    "tmp_dir=\"./tmp/\"\n",
    "prediction_dir=\"./prediction/\"\n",
    "\n",
    "firsttime=0\n",
    "frame_number=0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "height = 960\n",
    "width = 540\n",
    "\n",
    "\n",
    "\n",
    "# --------- 3. model define ---------\n",
    "print(\"...load BASNet...\")\n",
    "net = BASNet(3,1)\n",
    "net.load_state_dict(torch.load(model_dir))\n",
    "if torch.cuda.is_available():\n",
    "\tnet.cuda()\n",
    "net.eval()\n",
    "\n",
    "#4 body\n",
    "\n",
    "\n",
    "\n",
    "bkg=cv2.imread(bkg_file)\n",
    "\n",
    "videowriter = cv2.VideoWriter(output_video, fourcc, 20.0, (width*2,height))\n",
    "videowriter2 = cv2.VideoWriter(video_prueba, fourcc, 20.0, (width,height))\n",
    "\n",
    "cap = cv2.VideoCapture(input_file); \n",
    "cap2 = cv2.VideoCapture(input_file2); \n",
    "\n",
    "\n",
    "while(1): \n",
    "# read frames \n",
    "   print(\"Frame Number is\",frame_number);\n",
    "   frame_number=frame_number+1\n",
    "   ret2,img = cap.read();\n",
    "   ret3,img2 = cap2.read();\n",
    "\n",
    "   print(\"inferencing image:\",frame_number)\n",
    "   img_ret=process_image(img)\n",
    "   img_ret2=process_image(img2)\n",
    "\n",
    "\n",
    "\n",
    "   vis = np.concatenate((img, img2), axis=1)\n",
    "   vis2 = np.concatenate((img_ret, img_ret2), axis=1)\n",
    "\n",
    "   final1=cv2.bitwise_and(vis,vis2)\n",
    "   final15=cv2.bitwise_not(vis2)\n",
    "   final25=cv2.bitwise_and(bkg,final15)\n",
    "   final2=cv2.bitwise_or(bkg,vis2)\n",
    "#      final=final1+final2\n",
    "   final=cv2.bitwise_or(final1,final25)\n",
    "\n",
    "#      final=cv2.bitwise_and(img,bkg,mask=img_ret)\n",
    "\n",
    "\n",
    "#      img_ret=cv2.imread(img_ret_file)\n",
    "#      cv2.imshow(\"ejemplo\",final1)\n",
    "#      cv2.waitKey(0)\n",
    "#      cv2.imshow(\"ejemplo\",final2)\n",
    "#      cv2.waitKey(0)\n",
    "\n",
    "   videowriter.write(final)\n",
    "   videowriter2.write(final1)\n",
    "#   videowriter.write(img) \n",
    "   if frame_number==200 :\n",
    "            break;\n",
    "\n",
    " \n",
    "\n",
    "cap.release(); \n",
    "videowriter.release()\n",
    "videowriter2.release()\n",
    "\n",
    "  \n",
    "\n",
    "cv2.destroyAllWindows(); \n",
    "\n",
    "\n",
    "\n",
    "#generate_thumbnail(\"/home/jruano/devs/videos/video1.mp4\",\"fichero.jpg\",1,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
